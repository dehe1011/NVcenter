{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b4bccbd-22d4-4e1c-b867-709a886e4717",
   "metadata": {},
   "source": [
    "# Alessio Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4a92b9cc-fdfb-4c2e-ba02-8ee9b3d92513",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pennylane as qml\n",
    "\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.vec_env import SubprocVecEnv\n",
    "\n",
    "# Plotting and monitoring\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common import results_plotter\n",
    "from stable_baselines3.common.results_plotter import ts2xy, load_results\n",
    "from stable_baselines3.common.noise import NormalActionNoise\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "import os\n",
    "LOG_DIR = os.path.join( os.getcwd(), 'log')\n",
    "os.makedirs(LOG_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "562bc668-9358-4c4f-abd3-cf8a4a0393ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y, Z = qml.PauliX, qml.PauliY, qml.PauliZ\n",
    "Id = qml.Identity(wires=[0]).matrix()\n",
    "\n",
    "def layer(params):\n",
    "    \"\"\" one qubit \"\"\"\n",
    "    U = qml.RX(params[1],wires=0).matrix() @ qml.RZ(params[0],wires=0).matrix()\n",
    "    return U\n",
    "\n",
    "def profit(state, target_state):\n",
    "    \"\"\" state fidelity \"\"\"\n",
    "    return np.abs(np.trace(target_state.conj().T, state))\n",
    "\n",
    "def profit2(gate, target_gate):\n",
    "    \"\"\" gate fidelity \"\"\"\n",
    "    return np.abs(np.trace(target_gate.conj().T @ gate)) / 2**num_wires\n",
    "\n",
    "proj_0 = 1/2*(Z(wires= [0]) + qml.Identity(wires=[0]))\n",
    "proj_1 = 1/2*(-Z(wires= [0]) + qml.Identity(wires=[0]))\n",
    "ops =  [proj_0 @ (Z(1)/2),proj_1 @ (Z(1)/2),proj_1 @ (X(1)/2)]\n",
    "couplings = [-2*np.pi*0.158,-2*np.pi*(0.158-0.152),-2*np.pi*0.110]\n",
    "H = qml.dot(couplings,ops)\n",
    "\n",
    "def Ufree(t):\n",
    "    evo = qml.exp(H, -1j * t)\n",
    "    return evo.matrix()\n",
    "\n",
    "def Upulse(t, phi):\n",
    "    rabi_f = 0.5*2*np.pi\n",
    "    ops = [X(0) @ qml.Identity(1),Y(0) @ qml.Identity(1)]\n",
    "    couplings=[rabi_f*np.cos(phi),rabi_f*np.sin(phi)]\n",
    "    Hmw = qml.dot(couplings, ops)\n",
    "    \n",
    "    evo = qml.exp(H+Hmw, -1j * abs(t))\n",
    "    return evo.matrix()\n",
    "    \n",
    "def suter_layer(params):\n",
    "    \"\"\" two qubit indirect control. \"\"\"\n",
    "    U = Upulse([params[1],params[2]]) @ Ufree(params[0])\n",
    "    return U\n",
    "\n",
    "def F12_V6():\n",
    "    \"\"\" process fidelity \"\"\"\n",
    "    pass\n",
    "\n",
    "# Solution:\n",
    "# [0, np.pi/2], [np.pi/2, 0] = [2, 4], [4, 2]\n",
    "# [0, -np.pi/2], [-np.pi/2, 0] = [2, 0], [0, 2]\n",
    "# target_state = qml.Hadamard(wires=0).matrix() @ np.array([1,0])\n",
    "# state = layer([np.pi/2, 0]) @ layer([0, np.pi/2]) @ np.array([1,0])\n",
    "# profit(target_state, state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a274bc56-16ca-44f7-b6c9-c6a3c22e38da",
   "metadata": {},
   "source": [
    "## Example 1: Single qubit superposition state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "17bb677e-5b9b-4421-928c-43a9089b91dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "psi0 = np.array([1,0])\n",
    "\n",
    "class Parametric_env(gym.Env):\n",
    "    MAX_STEPS = 4\n",
    "    INFIDELITY_THRESHOLD = 1e-06\n",
    "\n",
    "    def __init__(self, env_conf):\n",
    "        self.target = env_conf[\"Target\"]\n",
    "        self.alpha = env_conf[\"Lagrange_time\"]\n",
    "\n",
    "        self.U = Id\n",
    "        self.psi=psi0\n",
    "        self.psi0=psi0\n",
    "        \n",
    "        self.action_space = gym.spaces.MultiDiscrete([5,5])\n",
    "        self.observation_space = gym.spaces.Box(low=-1, high=1, shape=(4,), dtype=np.float64)\n",
    "        \n",
    "    def _get_obs(self):\n",
    "        ob = np.concatenate([np.real(self.psi),np.imag(self.psi)])\n",
    "        return ob\n",
    "    \n",
    "    def reset(self,seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        self.U = Id\n",
    "        self.psi=psi0\n",
    "        self.fidelity = profit(self.psi,self.target)\n",
    "        self.count = 0\n",
    "        self.reward = 0\n",
    "        self.done = False\n",
    "        self.duration = 0\n",
    "        observation = self._get_obs()\n",
    "        self.info = {}\n",
    "\n",
    "        return observation,{}\n",
    "    \n",
    "    def _get_params(self,para):\n",
    "        az = 0\n",
    "    \n",
    "        if para==0:\n",
    "            az = -np.pi/2\n",
    "        elif para == 1:\n",
    "            az = -np.pi/4\n",
    "        elif para == 2:\n",
    "            az = 0\n",
    "        elif para == 3:\n",
    "            az = np.pi/4\n",
    "        elif para == 4:\n",
    "            az = np.pi/2\n",
    "        return az\n",
    "\n",
    "    def step(self, action):\n",
    "        if self.done:\n",
    "            print(\"EPISODE DONE!!!\")\n",
    "        elif (self.count == self.MAX_STEPS):\n",
    "            self.done = True\n",
    "        else:\n",
    "            assert self.action_space.contains(action)\n",
    "            self.count += 1\n",
    "            \n",
    "        self.params = [self._get_params(action[0]),self._get_params(action[1])] \n",
    "        op = layer(self.params)\n",
    "\n",
    "        self.U = op @ self.U  \n",
    "        self.psi = self.U @ self.psi0\n",
    "\n",
    "        self.fidelity = profit(self.psi,self.target)\n",
    "        self.info = {\"Fidelity\": self.fidelity}\n",
    "\n",
    "        if self.done:\n",
    "            self.reward = self.fidelity\n",
    "        else:\n",
    "            self.reward = 0\n",
    "\n",
    "        observation = self._get_obs()\n",
    "        return [observation, self.reward, self.done,self.done, self.info]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6b8934-1695-4ef8-92a4-31edfd07d3ed",
   "metadata": {},
   "source": [
    "### Training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d9626d65-ee78-462d-ab30-a3e7784a5327",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_state = np.array([[1,1],[1,-1]])/np.sqrt(2) @ np.array([1,0])\n",
    "env = Parametric_env(env_conf={\"Target\": target_state,\"Lagrange_time\":1})\n",
    "check_env(env, warn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0da60f9e-9022-486b-8910-291e75533662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "vec_env_test = make_vec_env(lambda:Parametric_env(env_conf={\"Target\": target_state, \"Lagrange_time\":0})\n",
    ", n_envs=1)\n",
    "\n",
    "vec_env = make_vec_env(lambda:Parametric_env(env_conf={\"Target\": target_state, \"Lagrange_time\":0})\n",
    ", n_envs=2,seed=0, vec_env_cls=SubprocVecEnv)\n",
    "\n",
    "model = PPO(\"MlpPolicy\", vec_env, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3b7fc885-2e64-4b12-8d34-5686c0e48d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward: 0.5 +/- 0.00\n"
     ]
    }
   ],
   "source": [
    "mean_reward, std_reward = evaluate_policy(model, vec_env_test, n_eval_episodes=10)\n",
    "print(f\"Mean reward: {mean_reward} +/- {std_reward:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e5db770-51d0-4779-a293-04c2cf63df9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 5        |\n",
      "|    ep_rew_mean     | 0.519    |\n",
      "| time/              |          |\n",
      "|    fps             | 641      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 4096     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5           |\n",
      "|    ep_rew_mean          | 0.52        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 456         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012180576 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.21       |\n",
      "|    explained_variance   | -1.22       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0239      |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    value_loss           | 0.0822      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5           |\n",
      "|    ep_rew_mean          | 0.579       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 415         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 29          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011038981 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.19       |\n",
      "|    explained_variance   | 0.00903     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0115      |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0195     |\n",
      "|    value_loss           | 0.0651      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5           |\n",
      "|    ep_rew_mean          | 0.609       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 392         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 41          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013475827 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.14       |\n",
      "|    explained_variance   | 0.0262      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0222     |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0202     |\n",
      "|    value_loss           | 0.0606      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 5          |\n",
      "|    ep_rew_mean          | 0.619      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 398        |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 51         |\n",
      "|    total_timesteps      | 20480      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01671819 |\n",
      "|    clip_fraction        | 0.174      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.09      |\n",
      "|    explained_variance   | 0.0219     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0147     |\n",
      "|    n_updates            | 40         |\n",
      "|    policy_gradient_loss | -0.0243    |\n",
      "|    value_loss           | 0.058      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5           |\n",
      "|    ep_rew_mean          | 0.697       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 60          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013279121 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.04       |\n",
      "|    explained_variance   | 0.0284      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00231     |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0205     |\n",
      "|    value_loss           | 0.0522      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5           |\n",
      "|    ep_rew_mean          | 0.729       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 408         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 70          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017682586 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.96       |\n",
      "|    explained_variance   | 0.0664      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0257     |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0256     |\n",
      "|    value_loss           | 0.044       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5           |\n",
      "|    ep_rew_mean          | 0.766       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 408         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 80          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017000208 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.87       |\n",
      "|    explained_variance   | 0.0676      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0147      |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0259     |\n",
      "|    value_loss           | 0.0371      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5           |\n",
      "|    ep_rew_mean          | 0.836       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 410         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 89          |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017928604 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.79       |\n",
      "|    explained_variance   | 0.0702      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00735     |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0266     |\n",
      "|    value_loss           | 0.0301      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 5          |\n",
      "|    ep_rew_mean          | 0.86       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 411        |\n",
      "|    iterations           | 10         |\n",
      "|    time_elapsed         | 99         |\n",
      "|    total_timesteps      | 40960      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01465711 |\n",
      "|    clip_fraction        | 0.159      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.7       |\n",
      "|    explained_variance   | 0.0558     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.00331   |\n",
      "|    n_updates            | 90         |\n",
      "|    policy_gradient_loss | -0.0235    |\n",
      "|    value_loss           | 0.0194     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5           |\n",
      "|    ep_rew_mean          | 0.885       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 410         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 109         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016292516 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.58       |\n",
      "|    explained_variance   | 0.0651      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0342     |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0247     |\n",
      "|    value_loss           | 0.0155      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5           |\n",
      "|    ep_rew_mean          | 0.893       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 411         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 119         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019192897 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.45       |\n",
      "|    explained_variance   | 0.0853      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0198     |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.03       |\n",
      "|    value_loss           | 0.0132      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5           |\n",
      "|    ep_rew_mean          | 0.932       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 412         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 129         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018614858 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.31       |\n",
      "|    explained_variance   | 0.0831      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00805    |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0335     |\n",
      "|    value_loss           | 0.00949     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x2627858bf90>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(50_000)\n",
    "# model.save(\"Simple_example\")\n",
    "# model_loaded = PPO.load(\"Simple_example\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edafa242-48c3-42bd-ac13-bb4c41cf1126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward: 1.0 +/- 0.00\n"
     ]
    }
   ],
   "source": [
    "mean_reward, std_reward = evaluate_policy(model, vec_env_test, n_eval_episodes=10)\n",
    "print(f\"Mean reward: {mean_reward} +/- {std_reward:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3c7b1b7-193d-4e61-bdad-2d15f12833a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1\n",
      "Action:  [[1 1]\n",
      " [3 2]]\n",
      "reward= [0 0]\n",
      "Fidelity: ({'Fidelity': np.float64(0.5000000000000001), 'TimeLimit.truncated': False}, {'Fidelity': np.float64(0.4999999999999999), 'TimeLimit.truncated': False})\n",
      "Step 2\n",
      "Action:  [[0 4]\n",
      " [1 3]]\n",
      "reward= [0 0]\n",
      "Fidelity: ({'Fidelity': np.float64(0.8535533905932742), 'TimeLimit.truncated': False}, {'Fidelity': np.float64(0.4999999999999999), 'TimeLimit.truncated': False})\n",
      "Step 3\n",
      "Action:  [[3 0]\n",
      " [3 0]]\n",
      "reward= [0 0]\n",
      "Fidelity: ({'Fidelity': np.float64(1.0000000000000004), 'TimeLimit.truncated': False}, {'Fidelity': np.float64(0.7499999999999999), 'TimeLimit.truncated': False})\n",
      "Step 4\n",
      "Action:  [[2 4]\n",
      " [1 3]]\n",
      "reward= [0 0]\n",
      "Fidelity: ({'Fidelity': np.float64(1.0000000000000009), 'TimeLimit.truncated': False}, {'Fidelity': np.float64(0.9267766952966368), 'TimeLimit.truncated': False})\n",
      "Step 5\n",
      "Action:  [[2 4]\n",
      " [2 2]]\n",
      "reward= [1.        0.9267767]\n",
      "Fidelity: ({'Fidelity': np.float64(1.0000000000000009), 'episode': {'r': 1.0, 'l': 5, 't': 136.604352}, 'TimeLimit.truncated': False, 'terminal_observation': array([ 0.65328148,  0.65328148, -0.27059805, -0.27059805])}, {'Fidelity': np.float64(0.9267766952966368), 'episode': {'r': 0.926777, 'l': 5, 't': 136.605347}, 'TimeLimit.truncated': False, 'terminal_observation': array([ 0.85355339,  0.5       ,  0.        , -0.14644661])})\n",
      "Goal reached Fidelity= ({'Fidelity': np.float64(1.0000000000000009), 'episode': {'r': 1.0, 'l': 5, 't': 136.604352}, 'TimeLimit.truncated': False, 'terminal_observation': array([ 0.65328148,  0.65328148, -0.27059805, -0.27059805])}, {'Fidelity': np.float64(0.9267766952966368), 'episode': {'r': 0.926777, 'l': 5, 't': 136.605347}, 'TimeLimit.truncated': False, 'terminal_observation': array([ 0.85355339,  0.5       ,  0.        , -0.14644661])})\n"
     ]
    }
   ],
   "source": [
    "obs = vec_env.reset()\n",
    "n_steps = 8\n",
    "for step in range(n_steps):\n",
    "    action, _ = model.predict(obs, deterministic= False)\n",
    "    print(f\"Step {step + 1}\")\n",
    "    print(\"Action: \", action)\n",
    "    obs, reward, done, info = vec_env.step(action)\n",
    "    print(\"reward=\", reward)\n",
    "    print(\"Fidelity:\", info)\n",
    "    if done.all():\n",
    "        if info[0][\"Fidelity\"] > 0.99:\n",
    "            print(\"Goal reached\", \"Fidelity=\", info)\n",
    "        else:\n",
    "            print(\" Max number of layers\", \"Fidelity=\", info[0][\"Fidelity\"],\"Fidelity=\",info[1][\"Fidelity\"])\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae49aa3e-a2d1-440d-b617-c4633830f125",
   "metadata": {},
   "source": [
    "### Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "66a04d46-d493-47ed-a096-fd92ce67428f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveOnBestTrainingRewardCallback(BaseCallback):\n",
    "    def __init__(self, check_freq, log_dir, verbose=1):\n",
    "        \n",
    "        super().__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.log_dir = log_dir\n",
    "        self.save_path = os.path.join(log_dir, \"best_model\")\n",
    "        self.best_mean_reward = -np.inf\n",
    "\n",
    "    def _on_step(self):\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "\n",
    "            # Retrieve training reward\n",
    "            x, y = ts2xy(load_results(self.log_dir), \"timesteps\")\n",
    "            if len(x) > 0:\n",
    "                # Mean training reward over the last 100 episodes\n",
    "                mean_reward = np.mean(y[-100:])\n",
    "                if self.verbose > 0:\n",
    "                    print(f\"Num timesteps: {self.num_timesteps}\")\n",
    "                    print(\n",
    "                        f\"Best mean reward: {self.best_mean_reward:.2f} - Last mean reward per episode: {mean_reward:.2f}\"\n",
    "                    )\n",
    "\n",
    "                # New best model, you could save the agent here\n",
    "                if mean_reward > self.best_mean_reward:\n",
    "                    self.best_mean_reward = mean_reward\n",
    "                    # Example for saving best model\n",
    "                    if self.verbose > 0:\n",
    "                        print(f\"Saving new best model to {self.save_path}.zip\")\n",
    "                    self.model.save(self.save_path)\n",
    "\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "19433e24-eba5-452b-b3da-87dd57084374",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Num timesteps: 1000\n",
      "Best mean reward: -inf - Last mean reward per episode: 0.50\n",
      "Saving new best model to C:\\Users\\Dennis Herb\\OneDrive\\2_Uni\\Doktor\\python_projects\\NVcenter\\development\\log\\best_model.zip\n",
      "Num timesteps: 2000\n",
      "Best mean reward: 0.50 - Last mean reward per episode: 0.54\n",
      "Saving new best model to C:\\Users\\Dennis Herb\\OneDrive\\2_Uni\\Doktor\\python_projects\\NVcenter\\development\\log\\best_model.zip\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 5        |\n",
      "|    ep_rew_mean     | 0.536    |\n",
      "| time/              |          |\n",
      "|    fps             | 687      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "Num timesteps: 3000\n",
      "Best mean reward: 0.54 - Last mean reward per episode: 0.49\n",
      "Num timesteps: 4000\n",
      "Best mean reward: 0.54 - Last mean reward per episode: 0.47\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5           |\n",
      "|    ep_rew_mean          | 0.486       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 508         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012423643 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.21       |\n",
      "|    explained_variance   | -0.653      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00598     |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0183     |\n",
      "|    value_loss           | 0.0961      |\n",
      "-----------------------------------------\n",
      "Num timesteps: 5000\n",
      "Best mean reward: 0.54 - Last mean reward per episode: 0.52\n",
      "Num timesteps: 6000\n",
      "Best mean reward: 0.54 - Last mean reward per episode: 0.57\n",
      "Saving new best model to C:\\Users\\Dennis Herb\\OneDrive\\2_Uni\\Doktor\\python_projects\\NVcenter\\development\\log\\best_model.zip\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5           |\n",
      "|    ep_rew_mean          | 0.594       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 439         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010941016 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.19       |\n",
      "|    explained_variance   | -0.0291     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0299      |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0186     |\n",
      "|    value_loss           | 0.0672      |\n",
      "-----------------------------------------\n",
      "Num timesteps: 7000\n",
      "Best mean reward: 0.57 - Last mean reward per episode: 0.53\n",
      "Num timesteps: 8000\n",
      "Best mean reward: 0.57 - Last mean reward per episode: 0.53\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5           |\n",
      "|    ep_rew_mean          | 0.553       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 421         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 19          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009836534 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.16       |\n",
      "|    explained_variance   | -6.2e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00675     |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0183     |\n",
      "|    value_loss           | 0.0634      |\n",
      "-----------------------------------------\n",
      "Num timesteps: 9000\n",
      "Best mean reward: 0.57 - Last mean reward per episode: 0.68\n",
      "Saving new best model to C:\\Users\\Dennis Herb\\OneDrive\\2_Uni\\Doktor\\python_projects\\NVcenter\\development\\log\\best_model.zip\n",
      "Num timesteps: 10000\n",
      "Best mean reward: 0.68 - Last mean reward per episode: 0.64\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5           |\n",
      "|    ep_rew_mean          | 0.648       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 412         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 24          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013513258 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.12       |\n",
      "|    explained_variance   | 0.0119      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0312      |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0218     |\n",
      "|    value_loss           | 0.0636      |\n",
      "-----------------------------------------\n",
      "Num timesteps: 11000\n",
      "Best mean reward: 0.68 - Last mean reward per episode: 0.66\n",
      "Num timesteps: 12000\n",
      "Best mean reward: 0.68 - Last mean reward per episode: 0.64\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5           |\n",
      "|    ep_rew_mean          | 0.642       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 413         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 29          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014951771 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.05       |\n",
      "|    explained_variance   | 0.0217      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0275     |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0252     |\n",
      "|    value_loss           | 0.0507      |\n",
      "-----------------------------------------\n",
      "Num timesteps: 13000\n",
      "Best mean reward: 0.68 - Last mean reward per episode: 0.72\n",
      "Saving new best model to C:\\Users\\Dennis Herb\\OneDrive\\2_Uni\\Doktor\\python_projects\\NVcenter\\development\\log\\best_model.zip\n",
      "Num timesteps: 14000\n",
      "Best mean reward: 0.72 - Last mean reward per episode: 0.69\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5           |\n",
      "|    ep_rew_mean          | 0.724       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 413         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 34          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015466961 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.99       |\n",
      "|    explained_variance   | 0.0733      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0102      |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.025      |\n",
      "|    value_loss           | 0.0486      |\n",
      "-----------------------------------------\n",
      "Num timesteps: 15000\n",
      "Best mean reward: 0.72 - Last mean reward per episode: 0.74\n",
      "Saving new best model to C:\\Users\\Dennis Herb\\OneDrive\\2_Uni\\Doktor\\python_projects\\NVcenter\\development\\log\\best_model.zip\n",
      "Num timesteps: 16000\n",
      "Best mean reward: 0.74 - Last mean reward per episode: 0.77\n",
      "Saving new best model to C:\\Users\\Dennis Herb\\OneDrive\\2_Uni\\Doktor\\python_projects\\NVcenter\\development\\log\\best_model.zip\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5           |\n",
      "|    ep_rew_mean          | 0.756       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 412         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 39          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015040871 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.92       |\n",
      "|    explained_variance   | 0.0677      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0107      |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0268     |\n",
      "|    value_loss           | 0.0422      |\n",
      "-----------------------------------------\n",
      "Num timesteps: 17000\n",
      "Best mean reward: 0.77 - Last mean reward per episode: 0.79\n",
      "Saving new best model to C:\\Users\\Dennis Herb\\OneDrive\\2_Uni\\Doktor\\python_projects\\NVcenter\\development\\log\\best_model.zip\n",
      "Num timesteps: 18000\n",
      "Best mean reward: 0.79 - Last mean reward per episode: 0.79\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5           |\n",
      "|    ep_rew_mean          | 0.78        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 413         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 44          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014330109 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.83       |\n",
      "|    explained_variance   | 0.0637      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00305    |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0229     |\n",
      "|    value_loss           | 0.0325      |\n",
      "-----------------------------------------\n",
      "Num timesteps: 19000\n",
      "Best mean reward: 0.79 - Last mean reward per episode: 0.81\n",
      "Saving new best model to C:\\Users\\Dennis Herb\\OneDrive\\2_Uni\\Doktor\\python_projects\\NVcenter\\development\\log\\best_model.zip\n",
      "Num timesteps: 20000\n",
      "Best mean reward: 0.81 - Last mean reward per episode: 0.83\n",
      "Saving new best model to C:\\Users\\Dennis Herb\\OneDrive\\2_Uni\\Doktor\\python_projects\\NVcenter\\development\\log\\best_model.zip\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5           |\n",
      "|    ep_rew_mean          | 0.792       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 412         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 49          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015924733 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.75       |\n",
      "|    explained_variance   | 0.0886      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00514    |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0243     |\n",
      "|    value_loss           | 0.0264      |\n",
      "-----------------------------------------\n",
      "Num timesteps: 21000\n",
      "Best mean reward: 0.83 - Last mean reward per episode: 0.83\n",
      "Num timesteps: 22000\n",
      "Best mean reward: 0.83 - Last mean reward per episode: 0.86\n",
      "Saving new best model to C:\\Users\\Dennis Herb\\OneDrive\\2_Uni\\Doktor\\python_projects\\NVcenter\\development\\log\\best_model.zip\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5           |\n",
      "|    ep_rew_mean          | 0.857       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 411         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 54          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014079114 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.64       |\n",
      "|    explained_variance   | 0.0887      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0336     |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0261     |\n",
      "|    value_loss           | 0.0214      |\n",
      "-----------------------------------------\n",
      "Num timesteps: 23000\n",
      "Best mean reward: 0.86 - Last mean reward per episode: 0.88\n",
      "Saving new best model to C:\\Users\\Dennis Herb\\OneDrive\\2_Uni\\Doktor\\python_projects\\NVcenter\\development\\log\\best_model.zip\n",
      "Num timesteps: 24000\n",
      "Best mean reward: 0.88 - Last mean reward per episode: 0.87\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5           |\n",
      "|    ep_rew_mean          | 0.887       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 411         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 59          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015968706 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.52       |\n",
      "|    explained_variance   | 0.118       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.000431    |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0288     |\n",
      "|    value_loss           | 0.0156      |\n",
      "-----------------------------------------\n",
      "Num timesteps: 25000\n",
      "Best mean reward: 0.88 - Last mean reward per episode: 0.91\n",
      "Saving new best model to C:\\Users\\Dennis Herb\\OneDrive\\2_Uni\\Doktor\\python_projects\\NVcenter\\development\\log\\best_model.zip\n",
      "Num timesteps: 26000\n",
      "Best mean reward: 0.91 - Last mean reward per episode: 0.89\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5           |\n",
      "|    ep_rew_mean          | 0.896       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 410         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 64          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013164281 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.43       |\n",
      "|    explained_variance   | 0.0517      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00656    |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0215     |\n",
      "|    value_loss           | 0.0137      |\n",
      "-----------------------------------------\n",
      "Num timesteps: 27000\n",
      "Best mean reward: 0.91 - Last mean reward per episode: 0.91\n",
      "Num timesteps: 28000\n",
      "Best mean reward: 0.91 - Last mean reward per episode: 0.90\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5           |\n",
      "|    ep_rew_mean          | 0.9         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 407         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 70          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013294417 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.31       |\n",
      "|    explained_variance   | 0.11        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0166     |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0242     |\n",
      "|    value_loss           | 0.0112      |\n",
      "-----------------------------------------\n",
      "Num timesteps: 29000\n",
      "Best mean reward: 0.91 - Last mean reward per episode: 0.91\n",
      "Num timesteps: 30000\n",
      "Best mean reward: 0.91 - Last mean reward per episode: 0.93\n",
      "Saving new best model to C:\\Users\\Dennis Herb\\OneDrive\\2_Uni\\Doktor\\python_projects\\NVcenter\\development\\log\\best_model.zip\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5           |\n",
      "|    ep_rew_mean          | 0.917       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 405         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 75          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013530135 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.2        |\n",
      "|    explained_variance   | 0.0678      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0248     |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0265     |\n",
      "|    value_loss           | 0.0102      |\n",
      "-----------------------------------------\n",
      "Num timesteps: 31000\n",
      "Best mean reward: 0.93 - Last mean reward per episode: 0.93\n",
      "Num timesteps: 32000\n",
      "Best mean reward: 0.93 - Last mean reward per episode: 0.95\n",
      "Saving new best model to C:\\Users\\Dennis Herb\\OneDrive\\2_Uni\\Doktor\\python_projects\\NVcenter\\development\\log\\best_model.zip\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 5          |\n",
      "|    ep_rew_mean          | 0.934      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 405        |\n",
      "|    iterations           | 16         |\n",
      "|    time_elapsed         | 80         |\n",
      "|    total_timesteps      | 32768      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01628495 |\n",
      "|    clip_fraction        | 0.187      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.1       |\n",
      "|    explained_variance   | 0.154      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0166    |\n",
      "|    n_updates            | 150        |\n",
      "|    policy_gradient_loss | -0.0277    |\n",
      "|    value_loss           | 0.00662    |\n",
      "----------------------------------------\n",
      "Num timesteps: 33000\n",
      "Best mean reward: 0.95 - Last mean reward per episode: 0.95\n",
      "Num timesteps: 34000\n",
      "Best mean reward: 0.95 - Last mean reward per episode: 0.97\n",
      "Saving new best model to C:\\Users\\Dennis Herb\\OneDrive\\2_Uni\\Doktor\\python_projects\\NVcenter\\development\\log\\best_model.zip\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5           |\n",
      "|    ep_rew_mean          | 0.966       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 86          |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015051153 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.96       |\n",
      "|    explained_variance   | 0.141       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0514     |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0285     |\n",
      "|    value_loss           | 0.00521     |\n",
      "-----------------------------------------\n",
      "Num timesteps: 35000\n",
      "Best mean reward: 0.97 - Last mean reward per episode: 0.97\n",
      "Saving new best model to C:\\Users\\Dennis Herb\\OneDrive\\2_Uni\\Doktor\\python_projects\\NVcenter\\development\\log\\best_model.zip\n",
      "Num timesteps: 36000\n",
      "Best mean reward: 0.97 - Last mean reward per episode: 0.96\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5           |\n",
      "|    ep_rew_mean          | 0.961       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 402         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 91          |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016490512 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.78       |\n",
      "|    explained_variance   | 0.176       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00917    |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0255     |\n",
      "|    value_loss           | 0.00345     |\n",
      "-----------------------------------------\n",
      "Num timesteps: 37000\n",
      "Best mean reward: 0.97 - Last mean reward per episode: 0.96\n",
      "Num timesteps: 38000\n",
      "Best mean reward: 0.97 - Last mean reward per episode: 0.98\n",
      "Saving new best model to C:\\Users\\Dennis Herb\\OneDrive\\2_Uni\\Doktor\\python_projects\\NVcenter\\development\\log\\best_model.zip\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5           |\n",
      "|    ep_rew_mean          | 0.973       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 399         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 97          |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012623468 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.66       |\n",
      "|    explained_variance   | 0.182       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0207     |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0231     |\n",
      "|    value_loss           | 0.00396     |\n",
      "-----------------------------------------\n",
      "Num timesteps: 39000\n",
      "Best mean reward: 0.98 - Last mean reward per episode: 0.97\n",
      "Num timesteps: 40000\n",
      "Best mean reward: 0.98 - Last mean reward per episode: 0.99\n",
      "Saving new best model to C:\\Users\\Dennis Herb\\OneDrive\\2_Uni\\Doktor\\python_projects\\NVcenter\\development\\log\\best_model.zip\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5           |\n",
      "|    ep_rew_mean          | 0.989       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 395         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 103         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017146314 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.52       |\n",
      "|    explained_variance   | 0.158       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0365     |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0197     |\n",
      "|    value_loss           | 0.00266     |\n",
      "-----------------------------------------\n",
      "Num timesteps: 41000\n",
      "Best mean reward: 0.99 - Last mean reward per episode: 0.99\n",
      "Num timesteps: 42000\n",
      "Best mean reward: 0.99 - Last mean reward per episode: 0.99\n",
      "Saving new best model to C:\\Users\\Dennis Herb\\OneDrive\\2_Uni\\Doktor\\python_projects\\NVcenter\\development\\log\\best_model.zip\n",
      "Num timesteps: 43000\n",
      "Best mean reward: 0.99 - Last mean reward per episode: 1.00\n",
      "Saving new best model to C:\\Users\\Dennis Herb\\OneDrive\\2_Uni\\Doktor\\python_projects\\NVcenter\\development\\log\\best_model.zip\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5           |\n",
      "|    ep_rew_mean          | 0.998       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 392         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 109         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016748123 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.4        |\n",
      "|    explained_variance   | 0.216       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0308     |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0198     |\n",
      "|    value_loss           | 0.00124     |\n",
      "-----------------------------------------\n",
      "Num timesteps: 44000\n",
      "Best mean reward: 1.00 - Last mean reward per episode: 1.00\n",
      "Num timesteps: 45000\n",
      "Best mean reward: 1.00 - Last mean reward per episode: 0.99\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 5         |\n",
      "|    ep_rew_mean          | 0.993     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 391       |\n",
      "|    iterations           | 22        |\n",
      "|    time_elapsed         | 114       |\n",
      "|    total_timesteps      | 45056     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0126821 |\n",
      "|    clip_fraction        | 0.0794    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.29     |\n",
      "|    explained_variance   | 0.241     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0311   |\n",
      "|    n_updates            | 210       |\n",
      "|    policy_gradient_loss | -0.0162   |\n",
      "|    value_loss           | 0.000635  |\n",
      "---------------------------------------\n",
      "Num timesteps: 46000\n",
      "Best mean reward: 1.00 - Last mean reward per episode: 1.00\n",
      "Num timesteps: 47000\n",
      "Best mean reward: 1.00 - Last mean reward per episode: 1.00\n",
      "Saving new best model to C:\\Users\\Dennis Herb\\OneDrive\\2_Uni\\Doktor\\python_projects\\NVcenter\\development\\log\\best_model.zip\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5            |\n",
      "|    ep_rew_mean          | 1            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 390          |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 120          |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0088426685 |\n",
      "|    clip_fraction        | 0.117        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.24        |\n",
      "|    explained_variance   | 0.233        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0129      |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.0114      |\n",
      "|    value_loss           | 0.000588     |\n",
      "------------------------------------------\n",
      "Num timesteps: 48000\n",
      "Best mean reward: 1.00 - Last mean reward per episode: 1.00\n",
      "Num timesteps: 49000\n",
      "Best mean reward: 1.00 - Last mean reward per episode: 1.00\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5           |\n",
      "|    ep_rew_mean          | 0.999       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 387         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 126         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010745391 |\n",
      "|    clip_fraction        | 0.0659      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.17       |\n",
      "|    explained_variance   | 0.332       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0136      |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.00684    |\n",
      "|    value_loss           | 0.00036     |\n",
      "-----------------------------------------\n",
      "Num timesteps: 50000\n",
      "Best mean reward: 1.00 - Last mean reward per episode: 1.00\n",
      "Num timesteps: 51000\n",
      "Best mean reward: 1.00 - Last mean reward per episode: 1.00\n",
      "Saving new best model to C:\\Users\\Dennis Herb\\OneDrive\\2_Uni\\Doktor\\python_projects\\NVcenter\\development\\log\\best_model.zip\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5           |\n",
      "|    ep_rew_mean          | 0.998       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 386         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 132         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007943921 |\n",
      "|    clip_fraction        | 0.0776      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.12       |\n",
      "|    explained_variance   | 0.448       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0315     |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    value_loss           | 0.000252    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x277653f24d0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_env = Parametric_env(env_conf={\"Target\": target_state,\"Lagrange_time\":0})\n",
    "\n",
    "vec_env = Monitor(vec_env, LOG_DIR)\n",
    "callback = SaveOnBestTrainingRewardCallback(check_freq=1000, log_dir=LOG_DIR)\n",
    "\n",
    "model_monitor = PPO(\"MlpPolicy\", vec_env, verbose=1)\n",
    "model_monitor.learn(total_timesteps=50_000, callback=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d27046cb-b558-4609-aa56-5b223ced31f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(values, window):\n",
    "    weights = np.repeat(1.0, window) / window\n",
    "    return np.convolve(values, weights, \"valid\")\n",
    "\n",
    "def plot_results(log_dir, title=\"Learning Curve\"):\n",
    "\n",
    "    x, y = ts2xy(load_results(log_dir), \"timesteps\")\n",
    "    y = moving_average(y, window=50)\n",
    "    # Truncate x\n",
    "    x = x[len(x) - len(y) :]\n",
    "\n",
    "    fig = plt.figure(title)\n",
    "    plt.plot(x, y)\n",
    "    plt.xlabel(\"Number of Timesteps\")\n",
    "    plt.ylabel(\"Rewards\")\n",
    "    plt.title(title + \" Smoothed\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3f1fb193-ad8b-4e46-bc8a-1b0a7eed0a6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_results(LOG_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74648bc-ce89-4433-939b-2f52e3cffbcc",
   "metadata": {},
   "source": [
    "## Example 2: Hadamard gate on C13 spin (using Suter indirect control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662f1840-2f88-48f7-b74c-e58b8c388a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# two options for the observation: hot encoding of count, unitary + count/Max_STEPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fff2b5-a7ba-4908-95e0-60d17bc0d02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parametric_env(gym.Env):\n",
    "    MAX_STEPS = 3\n",
    "    INFIDELITY_THRESHOLD = 0.001\n",
    "\n",
    "    def __init__(self, env_conf):\n",
    "        self.target = env_conf[\"Target\"]\n",
    "        self.alpha = env_conf[\"Lagrange_time\"]\n",
    "\n",
    "        self.U = Id\n",
    "        self.action_space = spaces.Box(low=-1, high= 1, shape=(3,), dtype=np.float32)\n",
    "        self.observation_space = spaces.Box(low=-1, high=1, shape=(5,), dtype=np.float64)\n",
    "        # self.observation_space = spaces.Box(low=-1, high=1, shape=(33,), dtype=np.float64)\n",
    "\n",
    "    def _hot_encode(self,observation):\n",
    "        observation_encoded=np.zeros(5, np.float32)\n",
    "        observation_encoded[observation]=1\n",
    "        return observation_encoded\n",
    "\n",
    "    def _get_obs(self):\n",
    "        obs = self.count\n",
    "        ob = self._hot_encode(obs)\n",
    "        # v = self.count/self.MAX_STEPS\n",
    "        # ob = np.concatenate([np.real(self.U.reshape(16,)),np.imag(self.U.reshape(16,)),[v]])\n",
    "        return ob\n",
    "    \n",
    "    def reset(self,seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        self.U = Id\n",
    "        \n",
    "        self.fidelity = profit(self.U,self.target)\n",
    "        self.count = 0\n",
    "        self.reward = 0\n",
    "        self.done = False\n",
    "        self.duration = 0\n",
    "        observation = self._get_obs()\n",
    "        self.info = {}\n",
    "        return observation,{}\n",
    "    \n",
    "    def _get_angle(self,para):\n",
    "        az = np.pi*para\n",
    "        return az\n",
    "    \n",
    "    def _get_times(self,para):\n",
    "        az = 1*np.abs(para)\n",
    "        return az\n",
    "        \n",
    "    def _get_times2(self,para):\n",
    "        az = 1.6*np.abs(para)   \n",
    "        return az\n",
    "\n",
    "    def step(self, action):\n",
    "        if self.done:\n",
    "            print(\"EPISODE DONE!!!\")\n",
    "        elif (self.count == self.MAX_STEPS):\n",
    "            self.count+= 1\n",
    "            self.done = True\n",
    "        else:\n",
    "            assert self.action_space.contains(action)\n",
    "            self.count += 1\n",
    "\n",
    "        self.params = [self._get_times(action[0]),self._get_times2(action[1]),self._get_angle(action[2])] \n",
    "        op = suter_layer(self.params)\n",
    "\n",
    "        self.U = op @ self.U  \n",
    "        self.fidelity = profit(self.U,self.target)\n",
    "        self.info = {\"Fidelity\": self.fidelity}#,\"Pre\":Upre,\"Next\":self.U}\n",
    "\n",
    "        if self.done:\n",
    "            self.reward = F12_V6(self.target,self.U,1,1,1)\n",
    "        else:\n",
    "            self.reward = 0\n",
    "\n",
    "        observation = self._get_obs()\n",
    "        return [observation, self.reward, self.done,self.done, self.info]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becfbc4f-bac1-42ba-a3e2-c78f8af9beba",
   "metadata": {},
   "source": [
    "### Training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a110d6cd-af32-476b-95a6-1d1dbcecf83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_gate = np.kron(np.eye(2), np.array([[1,1],[1,-1]])/np.sqrt(2) )\n",
    "env = Parametric_env(env_conf={\"Target\": target_gate,\"Lagrange_time\":1})\n",
    "check_env(env, warn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb6ecc5-ea9f-4003-ae32-0a8f3cf49406",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_env_test = make_vec_env(lambda:Parametric_env(env_conf={\"Target\": target_state,\"Lagrange_time\":0})\n",
    ", n_envs=1)\n",
    "\n",
    "vec_env = make_vec_env(lambda:Parametric_env(env_conf={\"Target\": target_state,\"Lagrange_time\":0})\n",
    ", n_envs=12,seed=0, vec_env_cls=SubprocVecEnv)\n",
    "\n",
    "model = PPO(\"MlpPolicy\", vec_env, learning_rate=0.00005,gamma=0.9996,n_steps=209,batch_size=209,clip_range=0.2, n_epochs=10,ent_coef=0.001, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e934bc1-faa7-4a3a-a0f4-5f75472cf357",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_reward, std_reward = evaluate_policy(model, vec_env_test, n_eval_episodes=10)\n",
    "print(f\"Mean reward: {mean_reward} +/- {std_reward:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bee649-73ca-4454-a257-0dad102b0bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.learn(5_000)\n",
    "# model_vec.save(\"Hadamard_QB2_Single_shot_on_qubit2_5Mshots_PPO\")\n",
    "# model_loaded = PPO.load(\"Hadamard_QB2_Single_shot_on_qubit2_5Mshots_PPO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2112df6f-9d9f-4684-8405-956135c941bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_reward, std_reward = evaluate_policy(model, vec_env_test, n_eval_episodes=10)\n",
    "print(f\"Mean reward: {mean_reward} +/- {std_reward:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef44ca30-7a1f-42e2-9746-68bf122dd1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = vec_env.reset()\n",
    "n_steps = 8\n",
    "actions_list = [] # can be used to calculate fidelities \n",
    "for step in range(n_steps):\n",
    "    action, _ = model_vec.predict(obs, deterministic= False)\n",
    "    print(f\"Step {step + 1}\")\n",
    "    print(\"Action: \", [action[0][i] for i in range(3)])\n",
    "    actions_list.append(action)\n",
    "    obs, reward, done, info = vec_env.step(action)\n",
    "    print(\"reward=\", reward,info, \"done=\", done)\n",
    "    if done.all():\n",
    "        if info[0][\"Fidelity\"] > 0.99:\n",
    "            print(\"Goal reached\", \"Fidelity=\", info[0])\n",
    "        else:\n",
    "            print(\" Max number of layers\", \"Fidelity=\", info)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b71627-d1c6-4601-a897-5dc2dc5b2b32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
