{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fba7ae3-bedf-4d8e-b0d7-2af6a282b06b",
   "metadata": {},
   "source": [
    "# Reinforcement Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "735faccf-2c35-4a3c-9085-2544b85b1264",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "ROOT_DIR = os.getcwd()[:os.getcwd().rfind('NVcenter')]+ 'NVcenter'\n",
    "os.chdir(ROOT_DIR)\n",
    "\n",
    "from NVcenter import *\n",
    "plt.style.use('NVcenter-default')\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import qutip as q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f0901a-e037-4640-b237-2435500de607",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Alessio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f19fd9e-54c7-49af-9bff-0adc5cc14070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# relaxation\n",
    "T1 = 6e-3 \n",
    "relax_rate = 0#1/T1 # relaxation\n",
    "relax_op = np.sqrt(relax_rate) * q.tensor(q.sigmap(), q.qeye(2))\n",
    "\n",
    "# dephasing\n",
    "T2 = 35e-6\n",
    "deph_rate = 0#(-1/T1+2/T2)/2 # dephasing\n",
    "deph_op = np.sqrt(0.5 * deph_rate) * q.tensor(q.sigmaz(), q.qeye(2))\n",
    "\n",
    "rabi_freq = 0.5e6\n",
    "proj_NV0 = q.ket2dm(q.basis(2,0))\n",
    "proj_NV1 = q.ket2dm(q.basis(2,1))\n",
    "\n",
    "def H_Suter():   \n",
    "    H = (-0.158e6) * q.tensor(proj_NV0, 0.5*q.sigmaz()) + (-0.158e6 + 0.152e6) * q.tensor(proj_NV1, 0.5*q.sigmaz()) + (-0.110e6) * q.tensor(proj_NV1, 0.5*q.sigmax()) \n",
    "    return 2 * np.pi * H\n",
    "\n",
    "def H_MW(phi):\n",
    "    H = rabi_freq * np.cos(phi)/2 * q.tensor(q.sigmax(), q.qeye(2)) + rabi_freq * np.sin(phi)/2 * q.tensor(q.sigmay(), q.qeye(2))\n",
    "    return 2 * np.pi * H\n",
    "\n",
    "def U_free_super(free_time):\n",
    "    H = H_Suter()\n",
    "    c_ops = [relax_op, deph_op]\n",
    "    L = q.liouvillian(H, c_ops)\n",
    "    return (free_time*L).expm()\n",
    "\n",
    "def U_pulse_super(pulse_time, phi):\n",
    "    H = H_Suter() + H_MW(phi)\n",
    "    c_ops = [relax_op, deph_op]\n",
    "    L = q.liouvillian(H, c_ops)\n",
    "    return (pulse_time*L).expm()\n",
    "    # return scipy.linalg.expm(pulse_time*L.full())\n",
    "\n",
    "def calc_superop(pulse_seq, num_pulses):\n",
    "    U = 1\n",
    "    for i in range(num_pulses):\n",
    "        free_time, pulse_time, phi = pulse_seq[i], pulse_seq[i+num_pulses], pulse_seq[i+2*num_pulses]\n",
    "        U = U_pulse_super(pulse_time, phi) * U_free_super(free_time) * U\n",
    "    if len(pulse_seq) != 3*num_pulses:\n",
    "        U = U_free_super(pulse_seq[-1]) * U\n",
    "    return U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2e5cff5-5ad8-444c-b070-45b37d30ce36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.9437899973536489)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_pulses = 3\n",
    "pulse_seq = [0.74e-6, 0.22e-6, 0.43e-6, 0.23e-6, 1.26e-6, 1.50e-6, 3*np.pi/2, 3*np.pi/2, np.pi/2, 0.89e-6] # Suter Hadamard\n",
    "superop = calc_superop(pulse_seq, num_pulses)\n",
    "\n",
    "target_hada = q.tensor(q.qeye(2), q.gates.hadamard_transform())\n",
    "target_superop = q.tensor(target_hada.conj(), target_hada)\n",
    "target_superop.dims = [target_hada.dims, target_hada.dims]\n",
    "\n",
    "calc_fidelity(superop, target_superop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e234051-edc1-42f7-8579-74cf43631b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.9797014459277309)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_pulses = 3\n",
    "pulse_seq = [3.78e-6, 2.11e-6, 2.15e-6, 1.88e-6, 3.96e-6, 1.9e-6, 0, np.pi/5, np.pi/2, 0.63e-6] # Suter CNOT\n",
    "superop = calc_superop(pulse_seq, num_pulses)\n",
    "\n",
    "target_cnot = q.tensor(proj_NV0, q.qeye(2))  -1j * q.tensor(proj_NV1, q.sigmax())\n",
    "target_superop = q.tensor(target_cnot.conj(), target_cnot)\n",
    "target_superop.dims = [target_cnot.dims, target_cnot.dims]\n",
    "\n",
    "calc_fidelity(superop, target_superop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23cd6ca-d862-4419-b56c-81a6768c785a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Lindblad Environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65957725-a178-405e-b70c-3174afb8da9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "class Parametric_env(gym.Env):\n",
    "    MAX_STEPS = 2\n",
    "    INFIDELITY_THRESHOLD = 0.1\n",
    "\n",
    "    def __init__(self, target_superop):\n",
    "        self.target_superop = target_superop\n",
    "\n",
    "        # action and observation spaces\n",
    "        self.action_space = gym.spaces.Box(low=-1, high= 1, shape=(3,), dtype=np.float32)\n",
    "        self.observation_space = gym.spaces.Box(low=-1, high=1, shape=(512,), dtype=np.float64)\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    def _get_obs(self):\n",
    "        A = self.superop.full()\n",
    "        real = A.flatten().real.tolist()\n",
    "        imag = A.flatten().imag.tolist()\n",
    "        return np.array(real + imag)\n",
    "\n",
    "    def reset(self,seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        self.superop = U_free_super(0)\n",
    "        self.fidelity = calc_fidelity(self.superop, self.target_superop)\n",
    "        self.count = 0\n",
    "        self.reward = 0\n",
    "        self.done = False\n",
    "        self.duration = 0\n",
    "        self.observation = self._get_obs()\n",
    "        self.info = {}\n",
    "\n",
    "        return self.observation,{}\n",
    "\n",
    "    def step(self, action):\n",
    "        if self.done:\n",
    "            print(\"EPISODE DONE!!!\")\n",
    "        elif (self.count == self.MAX_STEPS):\n",
    "            self.done = True\n",
    "        else:\n",
    "            assert self.action_space.contains(action)\n",
    "            self.count += 1\n",
    "            \n",
    "        pulse_seq = [\n",
    "            2.0e-6*np.abs(action[0]), #+ np.abs(0.1),\n",
    "            2.0e-6*np.abs(action[1]), #+ np.abs(0.1),\n",
    "            2*np.pi*action[2]\n",
    "        ]\n",
    "        superop_layer =  calc_superop(pulse_seq, 1)\n",
    "        \n",
    "        self.superop = superop_layer @ self.superop\n",
    "        self.fidelity = calc_fidelity(self.superop, self.target_superop)\n",
    "        self.info = {\"Fidelity\": self.fidelity}\n",
    "\n",
    "        if 1-self.fidelity < self.INFIDELITY_THRESHOLD:\n",
    "            self.done = True\n",
    "\n",
    "        if self.done:\n",
    "            self.reward = -np.log(1-self.fidelity)\n",
    "        else:\n",
    "            self.reward = 0\n",
    "\n",
    "        self.observation = self._get_obs()\n",
    "\n",
    "        return (self.observation, self.reward, self.done,self.done, self.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02690e4b-9cd3-4c76-80a3-be7165e519a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPISODE DONE!!!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.9437899973536489)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_hada = q.tensor(q.qeye(2), q.gates.hadamard_transform())\n",
    "target_superop = q.tensor(target_hada.conj(), target_hada)\n",
    "target_superop.dims = [target_hada.dims, target_hada.dims]\n",
    "\n",
    "param_env = Parametric_env(target_superop=target_superop) \n",
    "param_env.step( [0.74/2, 0.23/2, 3/4] )\n",
    "param_env.step( [0.22/2, 1.26/2, 3/4] )\n",
    "param_env.step([0.43/2, 1.50/2, 1/4] )\n",
    "param_env.step( [0.89/2, 0, 0] )\n",
    "param_env.fidelity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25243fb5-a18b-4f23-909e-a305e77977cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.env_checker import check_env\n",
    "\n",
    "param_env = Parametric_env(target_superop = U_free_super(0))\n",
    "check_env(param_env, warn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e26e354a-8fd6-4e68-84a4-3bdb93e9fd19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to ./ppo_cartpole_tensorboard/diss3/PPO_5\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 3        |\n",
      "|    ep_rew_mean     | 0.14     |\n",
      "| time/              |          |\n",
      "|    fps             | 697      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 1024     |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 3            |\n",
      "|    ep_rew_mean          | 0.166        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 665          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 3            |\n",
      "|    total_timesteps      | 2048         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.786431e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.3          |\n",
      "|    entropy_loss         | -4.26        |\n",
      "|    explained_variance   | -0.994       |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0151       |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00101     |\n",
      "|    std                  | 0.999        |\n",
      "|    value_loss           | 0.0894       |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 3             |\n",
      "|    ep_rew_mean          | 0.154         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 648           |\n",
      "|    iterations           | 3             |\n",
      "|    time_elapsed         | 4             |\n",
      "|    total_timesteps      | 3072          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00017237855 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.3           |\n",
      "|    entropy_loss         | -4.25         |\n",
      "|    explained_variance   | -0.186        |\n",
      "|    learning_rate        | 5e-05         |\n",
      "|    loss                 | 0.0111        |\n",
      "|    n_updates            | 20            |\n",
      "|    policy_gradient_loss | -0.00116      |\n",
      "|    std                  | 0.998         |\n",
      "|    value_loss           | 0.0574        |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 3             |\n",
      "|    ep_rew_mean          | 0.113         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 639           |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 6             |\n",
      "|    total_timesteps      | 4096          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013812323 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.3           |\n",
      "|    entropy_loss         | -4.25         |\n",
      "|    explained_variance   | -0.0393       |\n",
      "|    learning_rate        | 5e-05         |\n",
      "|    loss                 | 0.0132        |\n",
      "|    n_updates            | 30            |\n",
      "|    policy_gradient_loss | -0.00103      |\n",
      "|    std                  | 0.997         |\n",
      "|    value_loss           | 0.057         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 3             |\n",
      "|    ep_rew_mean          | 0.111         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 634           |\n",
      "|    iterations           | 5             |\n",
      "|    time_elapsed         | 8             |\n",
      "|    total_timesteps      | 5120          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00028459472 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.3           |\n",
      "|    entropy_loss         | -4.25         |\n",
      "|    explained_variance   | -0.0412       |\n",
      "|    learning_rate        | 5e-05         |\n",
      "|    loss                 | 0.0185        |\n",
      "|    n_updates            | 40            |\n",
      "|    policy_gradient_loss | -0.00172      |\n",
      "|    std                  | 0.996         |\n",
      "|    value_loss           | 0.06          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 3             |\n",
      "|    ep_rew_mean          | 0.131         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 627           |\n",
      "|    iterations           | 6             |\n",
      "|    time_elapsed         | 9             |\n",
      "|    total_timesteps      | 6144          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00019214908 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.3           |\n",
      "|    entropy_loss         | -4.24         |\n",
      "|    explained_variance   | -0.00824      |\n",
      "|    learning_rate        | 5e-05         |\n",
      "|    loss                 | 0.0026        |\n",
      "|    n_updates            | 50            |\n",
      "|    policy_gradient_loss | -0.00133      |\n",
      "|    std                  | 0.995         |\n",
      "|    value_loss           | 0.0425        |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 3             |\n",
      "|    ep_rew_mean          | 0.154         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 623           |\n",
      "|    iterations           | 7             |\n",
      "|    time_elapsed         | 11            |\n",
      "|    total_timesteps      | 7168          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00035177538 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.3           |\n",
      "|    entropy_loss         | -4.24         |\n",
      "|    explained_variance   | -0.0394       |\n",
      "|    learning_rate        | 5e-05         |\n",
      "|    loss                 | -0.00102      |\n",
      "|    n_updates            | 60            |\n",
      "|    policy_gradient_loss | -0.00171      |\n",
      "|    std                  | 0.995         |\n",
      "|    value_loss           | 0.0339        |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 3             |\n",
      "|    ep_rew_mean          | 0.133         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 625           |\n",
      "|    iterations           | 8             |\n",
      "|    time_elapsed         | 13            |\n",
      "|    total_timesteps      | 8192          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00019112026 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.3           |\n",
      "|    entropy_loss         | -4.24         |\n",
      "|    explained_variance   | 0.00808       |\n",
      "|    learning_rate        | 5e-05         |\n",
      "|    loss                 | 0.00221       |\n",
      "|    n_updates            | 70            |\n",
      "|    policy_gradient_loss | -0.00119      |\n",
      "|    std                  | 0.994         |\n",
      "|    value_loss           | 0.0347        |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 3             |\n",
      "|    ep_rew_mean          | 0.126         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 629           |\n",
      "|    iterations           | 9             |\n",
      "|    time_elapsed         | 14            |\n",
      "|    total_timesteps      | 9216          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00022042007 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.3           |\n",
      "|    entropy_loss         | -4.24         |\n",
      "|    explained_variance   | 0.00296       |\n",
      "|    learning_rate        | 5e-05         |\n",
      "|    loss                 | 0.00899       |\n",
      "|    n_updates            | 80            |\n",
      "|    policy_gradient_loss | -0.0013       |\n",
      "|    std                  | 0.993         |\n",
      "|    value_loss           | 0.0391        |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 3             |\n",
      "|    ep_rew_mean          | 0.141         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 632           |\n",
      "|    iterations           | 10            |\n",
      "|    time_elapsed         | 16            |\n",
      "|    total_timesteps      | 10240         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00023835275 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.3           |\n",
      "|    entropy_loss         | -4.23         |\n",
      "|    explained_variance   | 0.0661        |\n",
      "|    learning_rate        | 5e-05         |\n",
      "|    loss                 | 0.0245        |\n",
      "|    n_updates            | 90            |\n",
      "|    policy_gradient_loss | -0.00106      |\n",
      "|    std                  | 0.992         |\n",
      "|    value_loss           | 0.0598        |\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "\n",
    "target_hada = q.tensor(q.qeye(2), q.gates.hadamard_transform())\n",
    "target_superop = q.tensor(target_hada.conj(), target_hada)\n",
    "target_superop.dims = [target_hada.dims, target_hada.dims]\n",
    "\n",
    "param_env = Parametric_env(target_superop=target_superop)\n",
    "model = PPO(\"MlpPolicy\", param_env, learning_rate=0.00005,\n",
    "            gamma=0.99,n_steps=1024,batch_size=256,\n",
    "            clip_range=0.3, n_epochs=10,ent_coef=0.003, \n",
    "            verbose = 1,tensorboard_log=\"./ppo_cartpole_tensorboard/diss3/\").learn(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcde54b-8425-4730-b899-3e2730beae61",
   "metadata": {},
   "source": [
    "## Cluster Expansion Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4d60c46-afa5-4545-9c4b-dd172d4561b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "C13_pos = (8.728883757198979e-10, 0.0, 1.8558998769620693e-10) # Dominik\n",
    "register_config = [('NV', (0, 0, 0), 0, {}), ('C13', C13_pos, 0, {})]\n",
    "\n",
    "directory = os.getcwd()\n",
    "filename = os.path.join('baths', 'dominik_bath')\n",
    "bath_configs_nested = load_spin_baths(filename, directory)\n",
    "bath_configs = [item for sublist in bath_configs_nested for item in sublist]\n",
    "\n",
    "# Bell (Hadamard and CNOT)\n",
    "init_state = q.tensor( q.fock_dm(2,0), q.fock_dm(2,0) )\n",
    "bell_gate = get_cnot_gate(2, 0, 1) * get_hada_gate(2, 0)\n",
    "bell_state = bell_gate * init_state * bell_gate.dag()\n",
    "\n",
    "kwargs = dict(verbose=False, env_approx_level=\"gCCE1\", bath_configs=bath_configs, suter_method=True, target=bell_state)\n",
    "env = Environment2(register_config, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15d1b0c8-06cb-4dde-b45a-de4afb1ee864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.9847317310965369)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()\n",
    "env.step([2*0-1, 2*0.99813568/(2*np.pi)-1, 2*0.69459264/(2*np.pi)-1 ])\n",
    "env.step([ 2*4.06620465/5-1, 2*3.57557112/(2*np.pi)-1, 2*1.97327426/(2*np.pi)-1])\n",
    "env.step([2*1.57022726/5-1, 2*1.68300382/(2*np.pi)-1, 2*0.50816523/(2*np.pi)-1])\n",
    "env.step([2*1.50788214/5-1, 2*0-1, 2*0-1 ], instant_pulses=True)\n",
    "env.fidelity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee270ccf-7681-4f55-924b-3f52913e6057",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.env_checker import check_env\n",
    "check_env(env, warn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a24d3546-4ab5-4c16-b2d1-773385a37daa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to ./ppo_cartpole_tensorboard/diss3/PPO_29\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 4        |\n",
      "|    ep_rew_mean     | 0.322    |\n",
      "| time/              |          |\n",
      "|    fps             | 50       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 20       |\n",
      "|    total_timesteps | 1024     |\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "\n",
    "kwargs = dict(verbose=False, env_approx_level=\"gCCE1\", bath_configs=bath_configs, suter_method=True, target=bell_state)\n",
    "env = Environment2(register_config, **kwargs)\n",
    "\n",
    "model = PPO(\"MlpPolicy\", env, learning_rate=0.00005,\n",
    "            gamma=0.99,n_steps=1024,batch_size=256,\n",
    "            clip_range=0.3, n_epochs=10,ent_coef=0.003, \n",
    "            verbose = 1,tensorboard_log=\"./ppo_cartpole_tensorboard/diss3/\").learn(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d7931f34-448b-406a-a9dc-273f3edecb39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to ./ppo_cartpole_tensorboard/diss3/PPO_28\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 4        |\n",
      "|    ep_rew_mean     | 0.375    |\n",
      "| time/              |          |\n",
      "|    fps             | 117      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 8        |\n",
      "|    total_timesteps | 1024     |\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "\n",
    "kwargs = dict(verbose=False, env_approx_level=\"gCCE0\", bath_configs=bath_configs, suter_method=True, target=bell_state)\n",
    "env = Environment2(register_config, **kwargs)\n",
    "\n",
    "model = PPO(\"MlpPolicy\", env, learning_rate=0.00005,\n",
    "            gamma=0.99,n_steps=1024,batch_size=256,\n",
    "            clip_range=0.3, n_epochs=10,ent_coef=0.003, \n",
    "            verbose = 1,tensorboard_log=\"./ppo_cartpole_tensorboard/diss3/\").learn(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d8ce6973-6b7a-4402-bba6-bb76ed9c0b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1\n",
      "Action:  [np.float32(-0.00935421), np.float32(-0.020883545), np.float32(-0.0066122487)]\n",
      "reward= [0.] fidelity= 0.0005567095795421482 done= [False]\n",
      "Step 2\n",
      "Action:  [np.float32(-0.007822891), np.float32(-0.0066960733), np.float32(0.011714209)]\n",
      "reward= [0.] fidelity= 0.2300443675468704 done= [False]\n",
      "Step 3\n",
      "Action:  [np.float32(-0.007455373), np.float32(-0.013428304), np.float32(-0.0022534973)]\n",
      "reward= [0.] fidelity= 0.27681449731612284 done= [False]\n",
      "Step 4\n",
      "Action:  [np.float32(0.003688519), np.float32(-0.0028641312), np.float32(0.009643178)]\n",
      "reward= [0.6000857] fidelity= 0.45123537254091994 done= [ True]\n",
      " Max number of layers Fidelity= [{'Fidelity': np.float64(0.45123537254091994), 'episode': {'r': 0.600086, 'l': 4, 't': 0.031826}, 'TimeLimit.truncated': False, 'terminal_observation': array([ 9.24476903e-01,  2.61246171e-01,  2.78832107e-02, -1.13344043e-02,\n",
      "        2.61246171e-01,  7.40681101e-02,  7.98507638e-03, -2.86109335e-03,\n",
      "        2.78832107e-02,  7.98507638e-03,  9.52336202e-04, -1.59889868e-04,\n",
      "       -1.13344043e-02, -2.86109335e-03, -1.59889868e-04,  6.62651128e-04,\n",
      "        2.77555756e-17,  1.39986895e-02,  7.87507065e-03,  2.12627614e-02,\n",
      "       -1.39986895e-02, -1.38777878e-17,  1.79855137e-03,  6.19141540e-03,\n",
      "       -7.87507065e-03, -1.79855137e-03, -2.71050543e-19,  7.44633377e-04,\n",
      "       -2.12627614e-02, -6.19141540e-03, -7.44633377e-04,  1.35525272e-19])}]\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "vec_env = make_vec_env(lambda:Environment2(register_config, **kwargs), n_envs=1)\n",
    "\n",
    "obs = vec_env.reset()\n",
    "n_steps = 17\n",
    "for step in range(n_steps):\n",
    "    action, _ = model.predict(obs, deterministic= True)\n",
    "    print(f\"Step {step + 1}\")\n",
    "    print(\"Action: \", [action[0][i] for i in range(3)])\n",
    "    obs, reward, done, info = vec_env.step(action)\n",
    "    #print(\"obs=\", obs, \"reward=\", reward, \"done=\", done)\n",
    "    print(\"reward=\", reward,\"fidelity=\",info[0][\"Fidelity\"], \"done=\", done)\n",
    "    #vec_env.render()\n",
    "    if done:\n",
    "        # Note that the VecEnv resets automatically\n",
    "        # when a done signal is encountered\n",
    "        if reward > 0.99:\n",
    "            print(\"Goal reached\", \"Fidelity=\", info[0])\n",
    "        else:\n",
    "            print(\" Max number of layers\", \"Fidelity=\", info)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730f7fa3-c374-4de0-960e-4f6a9836130d",
   "metadata": {},
   "source": [
    "## Open Quantum Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afe5c7c-cc4d-441b-a16b-5e3d97b8e9df",
   "metadata": {},
   "source": [
    "A good source is Hashim 2024 (https://arxiv.org/abs/2408.12064)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c68dfa0-0cc3-4b42-a644-7b503d7a9e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_process_fidelity(U, U_target):\n",
    "    \"\"\" Calculates the process fidelity in Eq. (237). \"\"\"\n",
    "    \n",
    "    dim = U.shape[0]\n",
    "    PTM_U = calc_pauli_transfer_matrix([U])\n",
    "    PTM_U_target = calc_pauli_transfer_matrix([U_target])\n",
    "    return (PTM_U * PTM_U_target.inv()).tr() / dim**2\n",
    "\n",
    "# Martinez2020 (10.1109/ACCESS.2020.3025619): amplitude-phase damping (APD) superoperator channel\n",
    "\n",
    "# gamma = 1-np.exp(-t/T1) # amplitude damping channel, eq.(8)\n",
    "# lam = 1-np.exp(t/T1-2*t/T2)  # dephasing channel, eq.(13)\n",
    "\n",
    "# eq. (15)\n",
    "# E0 = ((1+np.sqrt(1-gamma-(1-gamma)*lam))/2)*Id+((1-np.sqrt(1-gamma-(1-gamma)*lam))/2)*Z # eq.()\n",
    "# E1 = (np.sqrt(gamma)/2)*X+ 1j*(np.sqrt(gamma)/2)*Y\n",
    "# E2 = (np.sqrt((1-gamma)*lam)/2)*Id-(np.sqrt((1-gamma)*lam)/2)*Z\n",
    "\n",
    "# Schlimgen2022 (10.1103/PhysRevResearch.4.023216): eq.(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a234824-c5d2-4a35-b381-caf3a1453f0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
